# -*- coding: utf-8 -*-
"""
YouTubeæœç´¢API - GitHub Webhookç‰ˆæœ¬
ç”¨äºéƒ¨ç½²åˆ°GitHub Actionsï¼Œé€šè¿‡webhookè§¦å‘YouTubeè§†é¢‘æœç´¢

åŠŸèƒ½ï¼š
- æ¥æ”¶ç”¨æˆ·è¾“å…¥çš„æœç´¢å…³é”®è¯å’Œwebhook URL
- è°ƒç”¨YouTube Data APIæœç´¢è§†é¢‘
- è·å–è§†é¢‘è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
- å°†ç»“æœå‘é€åˆ°æŒ‡å®šçš„webhookï¼ˆå¦‚é£ä¹¦å¤šç»´è¡¨æ ¼ï¼‰
"""

import os
import sys
import json
import time
import requests
import googleapiclient.discovery
import googleapiclient.errors
from datetime import datetime
from googleapiclient.http import build_http

def send_to_webhook(video_data, webhook_url):
    """å‘é€è§†é¢‘æ•°æ®åˆ°webhook"""
    try:
        headers = {
            'Content-Type': 'application/json',
            'User-Agent': 'YouTube-Search-Bot/2.0'
        }
        
        response = requests.post(
            webhook_url, 
            json=video_data, 
            headers=headers,
            timeout=30
        )
        
        if response.status_code == 200:
            print(f"âœ… Webhookå‘é€æˆåŠŸ: {response.status_code}")
            return True
        else:
            print(f"âŒ Webhookå‘é€å¤±è´¥: {response.status_code} - {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ Webhookå‘é€å¼‚å¸¸: {e}")
        return False

def get_video_comments(api_key, video_id, max_comments=50, webhook_url=None):
    """è·å–YouTubeè§†é¢‘çš„çƒ­é—¨è¯„è®º"""
    
    # APIé…ç½®
    api_service_name = "youtube"
    api_version = "v3"
    
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨GitHub Actionsç¯å¢ƒä¸­è¿è¡Œ
        is_github_actions = os.getenv('GITHUB_ACTIONS') == 'true'
        
        if is_github_actions:
            # GitHub Actionsç¯å¢ƒï¼Œç›´æ¥åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆæ— éœ€ä»£ç†ï¼‰
            youtube = googleapiclient.discovery.build(
                api_service_name, api_version, developerKey=api_key
            )
            print("ğŸš€ GitHub Actionsç¯å¢ƒï¼Œç›´æ¥è¿æ¥YouTube API")
        else:
            # æœ¬åœ°ç¯å¢ƒï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨ä»£ç†
            http_proxy = os.getenv('HTTP_PROXY')
            https_proxy = os.getenv('HTTPS_PROXY')
            socks_proxy = os.getenv('SOCKS_PROXY')
            
            proxy_url = socks_proxy or https_proxy or http_proxy
            
            if proxy_url:
                # ä½¿ç”¨ä»£ç†åˆ›å»ºHTTPå®¢æˆ·ç«¯
                import httplib2
                import socks
                
                if socks_proxy:
                    # SOCKSä»£ç†
                    proxy_parts = socks_proxy.replace('socks5://', '').replace('socks4://', '').split(':')
                    proxy_host = proxy_parts[0]
                    proxy_port = int(proxy_parts[1]) if len(proxy_parts) > 1 else 1080
                    proxy_type = socks.PROXY_TYPE_SOCKS5 if 'socks5' in socks_proxy else socks.PROXY_TYPE_SOCKS4
                    
                    http = httplib2.Http(proxy_info=httplib2.ProxyInfo(
                        proxy_type=proxy_type,
                        proxy_host=proxy_host,
                        proxy_port=proxy_port
                    ))
                else:
                    # HTTP/HTTPSä»£ç†
                    proxy_parts = proxy_url.replace('http://', '').replace('https://', '').split(':')
                    proxy_host = proxy_parts[0]
                    proxy_port = int(proxy_parts[1]) if len(proxy_parts) > 1 else 8080
                    
                    http = httplib2.Http(proxy_info=httplib2.ProxyInfo(
                        proxy_type=httplib2.socks.PROXY_TYPE_HTTP,
                        proxy_host=proxy_host,
                        proxy_port=proxy_port
                    ))
                
                youtube = googleapiclient.discovery.build(
                    api_service_name, api_version, developerKey=api_key, http=http
                )
                print(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxy_url}")
            else:
                # åˆ›å»ºYouTube APIå®¢æˆ·ç«¯ï¼ˆæ— ä»£ç†ï¼‰
                youtube = googleapiclient.discovery.build(
                    api_service_name, api_version, developerKey=api_key
                )
        
        print(f"ğŸ’¬ æ­£åœ¨è·å–è§†é¢‘ {video_id} çš„è¯„è®º...")
        
        # é¦–å…ˆè·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
        video_request = youtube.videos().list(
            part="snippet,statistics",
            id=video_id
        )
        video_response = video_request.execute()
        
        if not video_response.get('items'):
            print("âŒ è§†é¢‘ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
            return None
            
        video_info = video_response['items'][0]
        video_snippet = video_info.get('snippet', {})
        video_stats = video_info.get('statistics', {})
        
        # è·å–è¯„è®º
        comments_request = youtube.commentThreads().list(
            part="snippet,replies",
            videoId=video_id,
            maxResults=min(max_comments, 100),  # YouTube APIæœ€å¤§æ”¯æŒ100æ¡
            order="relevance"  # æŒ‰ç›¸å…³æ€§æ’åºï¼ˆé€šå¸¸åŒ…å«ç‚¹èµæ•°ï¼‰
        )
        
        comments_response = comments_request.execute()
        
        # å¤„ç†è¯„è®ºæ•°æ®
        comments_data = []
        for item in comments_response.get('items', []):
            comment = item['snippet']['topLevelComment']['snippet']
            
            comment_data = {
                'author_name': comment.get('authorDisplayName', ''),
                'author_channel_url': comment.get('authorChannelUrl', ''),
                'text': comment.get('textDisplay', ''),
                'like_count': int(comment.get('likeCount', 0)),
                'published_at': comment.get('publishedAt', ''),
                'updated_at': comment.get('updatedAt', ''),
                'reply_count': item['snippet'].get('totalReplyCount', 0)
            }
            comments_data.append(comment_data)
        
        # æŒ‰ç‚¹èµæ•°æ’åº
        comments_data.sort(key=lambda x: x['like_count'], reverse=True)
        
        # é™åˆ¶è¿”å›æ•°é‡
        comments_data = comments_data[:max_comments]
        
        # æ„å»ºå®Œæ•´ç»“æœ
        result = {
            'video_info': {
                'video_id': video_id,
                'title': video_snippet.get('title', ''),
                'channel_title': video_snippet.get('channelTitle', ''),
                'channel_id': video_snippet.get('channelId', ''),
                'published_at': video_snippet.get('publishedAt', ''),
                'description': video_snippet.get('description', '')[:500] + '...' if len(video_snippet.get('description', '')) > 500 else video_snippet.get('description', ''),
                'view_count': int(video_stats.get('viewCount', 0)),
                'like_count': int(video_stats.get('likeCount', 0)),
                'comment_count': int(video_stats.get('commentCount', 0)),
                'video_url': f'https://www.youtube.com/watch?v={video_id}'
            },
            'comments': comments_data,
            'total_comments_fetched': len(comments_data),
            'fetch_timestamp': datetime.now().isoformat()
        }
        
        print(f"âœ… æˆåŠŸè·å– {len(comments_data)} æ¡è¯„è®º")
        
        # å¦‚æœæä¾›äº†webhook URLï¼Œå‘é€ç»“æœ
        if webhook_url:
            print(f"ğŸ“¤ æ­£åœ¨å‘é€ç»“æœåˆ°webhook...")
            send_success = send_to_webhook(result, webhook_url)
            if send_success:
                print("âœ… è¯„è®ºæ•°æ®å·²æˆåŠŸå‘é€åˆ°webhook")
            else:
                print("âŒ è¯„è®ºæ•°æ®å‘é€åˆ°webhookå¤±è´¥")
        
        return result
        
    except googleapiclient.errors.HttpError as e:
        error_details = json.loads(e.content.decode('utf-8'))
        error_reason = error_details.get('error', {}).get('errors', [{}])[0].get('reason', 'unknown')
        
        if error_reason == 'commentsDisabled':
            print("âŒ è¯¥è§†é¢‘çš„è¯„è®ºåŠŸèƒ½å·²è¢«ç¦ç”¨")
        elif error_reason == 'videoNotFound':
            print("âŒ è§†é¢‘ä¸å­˜åœ¨")
        else:
            print(f"âŒ è·å–è¯„è®ºæ—¶å‘ç”ŸAPIé”™è¯¯: {e}")
        
        return {
            'video_info': {'video_id': video_id, 'error': f'APIé”™è¯¯: {error_reason}'},
            'comments': [],
            'total_comments_fetched': 0,
            'fetch_timestamp': datetime.now().isoformat(),
            'error': str(e)
        }
        
    except Exception as e:
        print(f"âŒ è·å–è¯„è®ºæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'video_info': {'video_id': video_id, 'error': str(e)},
            'comments': [],
            'total_comments_fetched': 0,
            'fetch_timestamp': datetime.now().isoformat(),
            'error': str(e)
        }

def get_channel_videos(api_key, handle, max_results=50, webhook_url=None):
    """è·å–æŒ‡å®šé¢‘é“çš„æ‰€æœ‰è§†é¢‘ä¿¡æ¯ï¼ˆé€šè¿‡handleï¼‰"""
    
    # APIé…ç½®
    api_service_name = "youtube"
    api_version = "v3"
    
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨GitHub Actionsç¯å¢ƒä¸­è¿è¡Œ
        is_github_actions = os.getenv('GITHUB_ACTIONS') == 'true'
        
        if is_github_actions:
            # GitHub Actionsç¯å¢ƒï¼Œç›´æ¥åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆæ— éœ€ä»£ç†ï¼‰
            youtube = googleapiclient.discovery.build(
                api_service_name, api_version, developerKey=api_key
            )
            print("ğŸš€ GitHub Actionsç¯å¢ƒï¼Œç›´æ¥è¿æ¥YouTube API")
        else:
            # æœ¬åœ°ç¯å¢ƒï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨ä»£ç†
            http_proxy = os.getenv('HTTP_PROXY')
            https_proxy = os.getenv('HTTPS_PROXY')
            socks_proxy = os.getenv('SOCKS_PROXY')
            
            proxy_url = socks_proxy or https_proxy or http_proxy
            
            if proxy_url:
                # ä½¿ç”¨ä»£ç†åˆ›å»ºHTTPå®¢æˆ·ç«¯
                import httplib2
                import socks
                
                if socks_proxy:
                    # SOCKSä»£ç†
                    proxy_parts = socks_proxy.replace('socks5://', '').replace('socks4://', '').split(':')
                    proxy_host = proxy_parts[0]
                    proxy_port = int(proxy_parts[1]) if len(proxy_parts) > 1 else 1080
                    proxy_type = socks.PROXY_TYPE_SOCKS5 if 'socks5' in socks_proxy else socks.PROXY_TYPE_SOCKS4
                    
                    http = httplib2.Http(proxy_info=httplib2.ProxyInfo(
                        proxy_type=proxy_type,
                        proxy_host=proxy_host,
                        proxy_port=proxy_port
                    ))
                else:
                    # HTTP/HTTPSä»£ç†
                    proxy_parts = proxy_url.replace('http://', '').replace('https://', '').split(':')
                    proxy_host = proxy_parts[0]
                    proxy_port = int(proxy_parts[1]) if len(proxy_parts) > 1 else 8080
                    
                    http = httplib2.Http(proxy_info=httplib2.ProxyInfo(
                        proxy_type=httplib2.socks.PROXY_TYPE_HTTP,
                        proxy_host=proxy_host,
                        proxy_port=proxy_port
                    ))
                
                youtube = googleapiclient.discovery.build(
                    api_service_name, api_version, developerKey=api_key, http=http
                )
                print(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxy_url}")
            else:
                # åˆ›å»ºYouTube APIå®¢æˆ·ç«¯ï¼ˆæ— ä»£ç†ï¼‰
                youtube = googleapiclient.discovery.build(
                    api_service_name, api_version, developerKey=api_key
                )
        
        print(f"ğŸ“º æ­£åœ¨è·å–é¢‘é“ {handle} çš„è§†é¢‘ä¿¡æ¯...")
        
        # å¤„ç†handleæ ¼å¼ï¼šæ”¯æŒYouTubeé“¾æ¥å’Œç›´æ¥handle
        if handle.startswith('https://www.youtube.com/@'):
            # ä»YouTubeé“¾æ¥ä¸­æå–handle
            processed_handle = handle.replace('https://www.youtube.com/', '')
            print(f"ğŸ”— ä»é“¾æ¥æå–handle: {handle} -> {processed_handle}")
        elif handle.startswith('@'):
            # ç›´æ¥ä½¿ç”¨@handleæ ¼å¼
            processed_handle = handle
            print(f"ğŸ” ä½¿ç”¨handle: {processed_handle}")
        else:
            # å…¼å®¹æ—§æ ¼å¼ï¼šç›´æ¥æ·»åŠ @å‰ç¼€
            processed_handle = '@' + handle
            print(f"ğŸ”§ æ·»åŠ @å‰ç¼€: {handle} -> {processed_handle}")
        
        # ç›´æ¥é€šè¿‡forHandleå‚æ•°è·å–é¢‘é“ä¿¡æ¯
        channel_request = youtube.channels().list(
            part="snippet,statistics,contentDetails",
            forHandle=processed_handle
        )
        channel_response = channel_request.execute()
        
        if not channel_response.get('items'):
            print("âŒ é¢‘é“ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
            return None
            
        channel_info = channel_response['items'][0]
        channel_snippet = channel_info.get('snippet', {})
        channel_stats = channel_info.get('statistics', {})
        
        # è·å–é¢‘é“çš„ä¸Šä¼ æ’­æ”¾åˆ—è¡¨ID
        uploads_playlist_id = channel_info.get('contentDetails', {}).get('relatedPlaylists', {}).get('uploads')
        
        if not uploads_playlist_id:
            print("âŒ æ— æ³•è·å–é¢‘é“çš„ä¸Šä¼ æ’­æ”¾åˆ—è¡¨")
            return None
        
        # è·å–æ’­æ”¾åˆ—è¡¨ä¸­çš„è§†é¢‘
        all_videos = []
        next_page_token = None
        page_count = 0
        total_fetched = 0
        
        print(f"ğŸ“Š å¼€å§‹è·å–é¢‘é“è§†é¢‘ï¼Œç›®æ ‡æ•°é‡: {max_results}")
        
        while len(all_videos) < max_results:
            page_count += 1
            remaining_results = max_results - len(all_videos)
            current_max_results = min(50, remaining_results)  # YouTube APIå•æ¬¡æœ€å¤§50æ¡
            
            print(f"ğŸ“„ æ­£åœ¨è·å–ç¬¬ {page_count} é¡µï¼Œæœ¬é¡µç›®æ ‡: {current_max_results} æ¡")
            
            playlist_request = youtube.playlistItems().list(
                part="snippet,contentDetails",
                playlistId=uploads_playlist_id,
                maxResults=current_max_results,
                pageToken=next_page_token
            )
            
            playlist_response = playlist_request.execute()
            
            # æ”¶é›†è§†é¢‘ID
            video_ids = []
            for item in playlist_response.get('items', []):
                video_id = item.get('contentDetails', {}).get('videoId')
                if video_id:
                    video_ids.append(video_id)
            
            if not video_ids:
                print(f"âš ï¸ ç¬¬ {page_count} é¡µæ²¡æœ‰æ‰¾åˆ°è§†é¢‘ï¼Œåœæ­¢è·å–")
                break
            
            print(f"âœ… ç¬¬ {page_count} é¡µè·å–åˆ° {len(video_ids)} ä¸ªè§†é¢‘ID")
            
            # è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯
            videos_request = youtube.videos().list(
                part="snippet,statistics,contentDetails,status,recordingDetails,topicDetails",
                id=','.join(video_ids)
            )
            videos_response = videos_request.execute()
            
            # å¤„ç†è§†é¢‘æ•°æ®
            for video in videos_response.get('items', []):
                video_snippet = video.get('snippet', {})
                video_stats = video.get('statistics', {})
                video_content = video.get('contentDetails', {})
                video_status = video.get('status', {})
                video_recording = video.get('recordingDetails', {})
                video_topics = video.get('topicDetails', {})
                
                video_data = {
                    'video_id': video.get('id', ''),
                    'title': video_snippet.get('title', ''),
                    'description': video_snippet.get('description', ''),
                    'published_at': video_snippet.get('publishedAt', ''),
                    'duration': video_content.get('duration', ''),
                    'view_count': int(video_stats.get('viewCount', 0)),
                    'like_count': int(video_stats.get('likeCount', 0)),
                    'comment_count': int(video_stats.get('commentCount', 0)),
                    'privacy_status': video_status.get('privacyStatus', ''),
                    'video_url': f"https://www.youtube.com/watch?v={video.get('id', '')}",
                    'thumbnail_url': video_snippet.get('thumbnails', {}).get('high', {}).get('url', ''),
                    'tags': video_snippet.get('tags', []),
                    'category_id': video_snippet.get('categoryId', ''),
                    'default_language': video_snippet.get('defaultLanguage', ''),
                    'definition': video_content.get('definition', ''),
                    'caption': video_content.get('caption', ''),
                    # æ–°å¢å­—æ®µ
                    'thumbnails': video_snippet.get('thumbnails', {}),  # å®Œæ•´ç¼©ç•¥å›¾ä¿¡æ¯
                    'live_broadcast_content': video_snippet.get('liveBroadcastContent', ''),
                    'default_audio_language': video_snippet.get('defaultAudioLanguage', ''),
                    'dimension': video_content.get('dimension', ''),
                    'projection': video_content.get('projection', ''),
                    'has_custom_thumbnail': video_content.get('hasCustomThumbnail', False),
                    'upload_status': video_status.get('uploadStatus', ''),
                    'license': video_status.get('license', ''),
                    'embeddable': video_status.get('embeddable', True),
                    'public_stats_viewable': video_status.get('publicStatsViewable', True),
                    'made_for_kids': video_status.get('madeForKids', False),
                    # å½•åˆ¶è¯¦æƒ…ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
                    'recording_date': video_recording.get('recordingDate', ''),
                    'location_description': video_recording.get('locationDescription', ''),
                    'location': video_recording.get('location', {}),
                    # ä¸»é¢˜è¯¦æƒ…ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
                    'topic_ids': video_topics.get('topicIds', []),
                    'topic_categories': video_topics.get('topicCategories', [])
                }
                all_videos.append(video_data)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            next_page_token = playlist_response.get('nextPageToken')
            total_fetched = len(all_videos)
            
            print(f"ğŸ“ˆ å½“å‰å·²è·å– {total_fetched} ä¸ªè§†é¢‘")
            
            if not next_page_token:
                print(f"ğŸ“„ å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œæ€»å…±è·å–äº† {total_fetched} ä¸ªè§†é¢‘")
                break
            else:
                print(f"â¡ï¸ å­˜åœ¨ä¸‹ä¸€é¡µï¼Œç»§ç»­è·å–...")
                
            # å¦‚æœå·²ç»è·å–è¶³å¤Ÿçš„è§†é¢‘ï¼Œé€€å‡ºå¾ªç¯
            if len(all_videos) >= max_results:
                print(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ {max_results}ï¼Œåœæ­¢è·å–")
                break
        
        # æŒ‰è§‚çœ‹æ•°æ’åº
        all_videos.sort(key=lambda x: x['view_count'], reverse=True)
        
        # é™åˆ¶è¿”å›æ•°é‡
        all_videos = all_videos[:max_results]
        
        print(f"ğŸ“Š åˆ†é¡µè·å–å®Œæˆç»Ÿè®¡:")
        print(f"   - æ€»é¡µæ•°: {page_count}")
        print(f"   - å®é™…è·å–: {len(all_videos)} ä¸ªè§†é¢‘")
        print(f"   - ç›®æ ‡æ•°é‡: {max_results}")
        print(f"   - å·²æŒ‰è§‚çœ‹æ•°æ’åº")
        
        # è·å–å®é™…çš„é¢‘é“IDï¼ˆä»APIå“åº”ä¸­è·å–ï¼‰
        actual_channel_id = channel_info.get('id', '')
        
        # æ„å»ºå®Œæ•´ç»“æœ
        result = {
            'channel_info': {
                'channel_id': actual_channel_id,
                'handle': handle,
                'title': channel_snippet.get('title', ''),
                'description': channel_snippet.get('description', ''),
                'custom_url': channel_snippet.get('customUrl', ''),
                'published_at': channel_snippet.get('publishedAt', ''),
                'country': channel_snippet.get('country', ''),  # æ·»åŠ è¿™è¡Œ
                'thumbnail_url': channel_snippet.get('thumbnails', {}).get('high', {}).get('url', ''),
                'subscriber_count': int(channel_stats.get('subscriberCount', 0)),
                'video_count': int(channel_stats.get('videoCount', 0)),
                'view_count': int(channel_stats.get('viewCount', 0)),
                'channel_url': f"https://www.youtube.com/channel/{actual_channel_id}"
            },
            'videos': all_videos,
            'total_videos_fetched': len(all_videos),
            'fetch_timestamp': datetime.now().isoformat()
        }
        
        print(f"âœ… æˆåŠŸè·å–é¢‘é“ {channel_snippet.get('title', handle)} çš„ {len(all_videos)} ä¸ªè§†é¢‘")
        
        # å‘é€åˆ°webhook
        if webhook_url:
            print(f"ğŸ“¤ æ­£åœ¨å‘é€ç»“æœåˆ°webhook: {webhook_url}")
            success = send_to_webhook(result, webhook_url)
            if success:
                print("âœ… Webhookå‘é€æˆåŠŸ")
            else:
                print("âŒ Webhookå‘é€å¤±è´¥")
        
        return result
        
    except googleapiclient.errors.HttpError as e:
        error_msg = f"YouTube APIé”™è¯¯: {e}"
        print(f"âŒ {error_msg}")
        return {
            'channel_info': {'handle': handle, 'error': str(e)},
            'videos': [],
            'total_videos_fetched': 0,
            'fetch_timestamp': datetime.now().isoformat(),
            'error': str(e)
        }
        
    except Exception as e:
        print(f"âŒ è·å–é¢‘é“è§†é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'channel_info': {'handle': handle, 'error': str(e)},
            'videos': [],
            'total_videos_fetched': 0,
            'fetch_timestamp': datetime.now().isoformat(),
            'error': str(e)
        }

def search_youtube_videos(api_key, search_query, max_results=25, webhook_url=None):
    """æœç´¢YouTubeè§†é¢‘å¹¶è¿”å›ç»“æœï¼Œæ”¯æŒåˆ†é¡µè·å–æ›´å¤šç»“æœ"""
    
    # APIé…ç½®
    api_service_name = "youtube"
    api_version = "v3"
    
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨GitHub Actionsç¯å¢ƒä¸­è¿è¡Œ
        is_github_actions = os.getenv('GITHUB_ACTIONS') == 'true'
        
        if is_github_actions:
            # GitHub Actionsç¯å¢ƒï¼Œç›´æ¥åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆæ— éœ€ä»£ç†ï¼‰
            youtube = googleapiclient.discovery.build(
                api_service_name, api_version, developerKey=api_key
            )
            print("ğŸš€ GitHub Actionsç¯å¢ƒï¼Œç›´æ¥è¿æ¥YouTube API")
        else:
            # æœ¬åœ°ç¯å¢ƒï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ä½¿ç”¨ä»£ç†
            http_proxy = os.getenv('HTTP_PROXY')
            https_proxy = os.getenv('HTTPS_PROXY')
            socks_proxy = os.getenv('SOCKS_PROXY')
            
            proxy_url = socks_proxy or https_proxy or http_proxy
            
            if proxy_url:
                # ä½¿ç”¨ä»£ç†åˆ›å»ºHTTPå®¢æˆ·ç«¯
                import httplib2
                import socks
                
                if socks_proxy:
                    # SOCKSä»£ç†
                    proxy_parts = socks_proxy.replace('socks5://', '').replace('socks4://', '').split(':')
                    proxy_host = proxy_parts[0]
                    proxy_port = int(proxy_parts[1]) if len(proxy_parts) > 1 else 1080
                    proxy_type = socks.PROXY_TYPE_SOCKS5 if 'socks5' in socks_proxy else socks.PROXY_TYPE_SOCKS4
                    
                    http = httplib2.Http(proxy_info=httplib2.ProxyInfo(
                        proxy_type=proxy_type,
                        proxy_host=proxy_host,
                        proxy_port=proxy_port
                    ))
                else:
                    # HTTP/HTTPSä»£ç†
                    proxy_parts = proxy_url.replace('http://', '').replace('https://', '').split(':')
                    proxy_host = proxy_parts[0]
                    proxy_port = int(proxy_parts[1]) if len(proxy_parts) > 1 else 8080
                    
                    http = httplib2.Http(proxy_info=httplib2.ProxyInfo(
                        proxy_type=httplib2.socks.PROXY_TYPE_HTTP,
                        proxy_host=proxy_host,
                        proxy_port=proxy_port
                    ))
                
                youtube = googleapiclient.discovery.build(
                    api_service_name, api_version, developerKey=api_key, http=http
                )
                print(f"ğŸŒ ä½¿ç”¨ä»£ç†: {proxy_url}")
            else:
                # åˆ›å»ºYouTube APIå®¢æˆ·ç«¯ï¼ˆæ— ä»£ç†ï¼‰
                youtube = googleapiclient.discovery.build(
                    api_service_name, api_version, developerKey=api_key
                )

        # åˆ†é¡µè·å–æœç´¢ç»“æœ
        all_video_ids = []
        next_page_token = None
        search_requests_count = 0
        
        print(f"ğŸ” æ­£åœ¨æœç´¢: {search_query}")
        print(f"ğŸ“Š ç›®æ ‡ç»“æœæ•°: {max_results}")
        
        while len(all_video_ids) < max_results:
            # è®¡ç®—æœ¬æ¬¡è¯·æ±‚éœ€è¦è·å–çš„ç»“æœæ•°
            remaining_results = max_results - len(all_video_ids)
            current_max_results = min(50, remaining_results)  # YouTube APIå•æ¬¡æœ€å¤§50æ¡
            
            # æ„å»ºæœç´¢è¯·æ±‚
            search_request = youtube.search().list(
                part="snippet",
                q=search_query,
                maxResults=current_max_results,
                order="viewCount",
                type="video",  # åªæœç´¢è§†é¢‘
                pageToken=next_page_token
            )
        
            # æ‰§è¡Œæœç´¢è¯·æ±‚
            search_response = search_request.execute()
            search_requests_count += 1
            print(f"âœ… ç¬¬{search_requests_count}æ¬¡æœç´¢è¯·æ±‚æˆåŠŸï¼è·å–åˆ° {len(search_response.get('items', []))} æ¡ç»“æœ")
            
            # æ”¶é›†è§†é¢‘ID
            for item in search_response.get('items', []):
                video_id = item.get('id', {}).get('videoId')
                if video_id:
                    all_video_ids.append(video_id)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
            next_page_token = search_response.get('nextPageToken')
            if not next_page_token:
                print("ğŸ“„ å·²åˆ°è¾¾æœç´¢ç»“æœæœ«é¡µ")
                break
                
            # å¦‚æœå·²ç»è·å–è¶³å¤Ÿçš„ç»“æœï¼Œé€€å‡ºå¾ªç¯
            if len(all_video_ids) >= max_results:
                break
        
        # é™åˆ¶ç»“æœæ•°é‡
        all_video_ids = all_video_ids[:max_results]
        
        if not all_video_ids:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘")
            return []
            
        print(f"ğŸ“‹ æ€»å…±æ”¶é›†åˆ° {len(all_video_ids)} ä¸ªè§†é¢‘ID")
        print(f"ğŸ’° æœç´¢é…é¢æ¶ˆè€—: {search_requests_count * 100} å•ä½")
        
        # åˆ†æ‰¹è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯ï¼ˆYouTube APIé™åˆ¶å•æ¬¡æœ€å¤š50ä¸ªIDï¼‰
        all_video_details = []
        batch_size = 50
        videos_requests_count = 0
        
        for i in range(0, len(all_video_ids), batch_size):
            batch_ids = all_video_ids[i:i + batch_size]
            print(f"ğŸ“‹ å¤„ç†ç¬¬ {i//batch_size + 1} æ‰¹è§†é¢‘ ({len(batch_ids)} ä¸ª)")
            
            videos_request = youtube.videos().list(
                part="snippet,statistics,contentDetails,status,recordingDetails,topicDetails",
                id=','.join(batch_ids)
            )
            videos_response = videos_request.execute()
            videos_requests_count += 1
            all_video_details.extend(videos_response.get('items', []))
        
        print(f"ğŸ’° è§†é¢‘è¯¦æƒ…é…é¢æ¶ˆè€—: {videos_requests_count * 1} å•ä½")
        print(f"ğŸ’° æ€»é…é¢æ¶ˆè€—: {search_requests_count * 100 + videos_requests_count * 1} å•ä½")
        
        # æ„å»ºè§†é¢‘è¯¦ç»†ä¿¡æ¯å­—å…¸
        video_details = {}
        for video in all_video_details:
            video_id = video.get('id')
            if video_id:
                video_details[video_id] = {
                    'snippet': video.get('snippet', {}),
                    'statistics': video.get('statistics', {}),
                    'contentDetails': video.get('contentDetails', {}),
                    'status': video.get('status', {}),
                    'recordingDetails': video.get('recordingDetails', {}),
                    'topicDetails': video.get('topicDetails', {})
                }
        
        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„é¢‘é“ID
        unique_channel_ids = set()
        for video in all_video_details:
            channel_id = video.get('snippet', {}).get('channelId')
            if channel_id:
                unique_channel_ids.add(channel_id)
        
        # æ‰¹é‡è·å–é¢‘é“ä¿¡æ¯
        channel_info_dict = {}
        if unique_channel_ids:
            print(f"ğŸ“º æ­£åœ¨è·å– {len(unique_channel_ids)} ä¸ªé¢‘é“çš„è¯¦ç»†ä¿¡æ¯...")
            
            # åˆ†æ‰¹è·å–é¢‘é“ä¿¡æ¯ï¼ˆYouTube APIé™åˆ¶å•æ¬¡æœ€å¤š50ä¸ªIDï¼‰
            channel_batch_size = 50
            channel_ids_list = list(unique_channel_ids)
            
            for i in range(0, len(channel_ids_list), channel_batch_size):
                batch_channel_ids = channel_ids_list[i:i + channel_batch_size]
                print(f"ğŸ“‹ å¤„ç†ç¬¬ {i//channel_batch_size + 1} æ‰¹é¢‘é“ ({len(batch_channel_ids)} ä¸ª)")
                
                channels_request = youtube.channels().list(
                    part="snippet,statistics,brandingSettings,status,topicDetails,localizations",
                    id=','.join(batch_channel_ids)
                )
                channels_response = channels_request.execute()
                
                # å¤„ç†é¢‘é“ä¿¡æ¯
                for channel in channels_response.get('items', []):
                    channel_id = channel.get('id')
                    if channel_id:
                        channel_snippet = channel.get('snippet', {})
                        channel_stats = channel.get('statistics', {})
                        channel_branding = channel.get('brandingSettings', {})
                        channel_status = channel.get('status', {})
                        channel_topics = channel.get('topicDetails', {})
                        
                        channel_info_dict[channel_id] = {
                            'channel_id': channel_id,
                            'title': channel_snippet.get('title', ''),
                            'description': channel_snippet.get('description', ''),
                            'custom_url': channel_snippet.get('customUrl', ''),
                            'published_at': channel_snippet.get('publishedAt', ''),
                            'country': channel_snippet.get('country', ''),
                            'default_language': channel_snippet.get('defaultLanguage', ''),
                            'localized_title': channel_snippet.get('localized', {}).get('title', ''),
                            'localized_description': channel_snippet.get('localized', {}).get('description', ''),
                            'thumbnail_url': channel_snippet.get('thumbnails', {}).get('high', {}).get('url', ''),
                            'subscriber_count': int(channel_stats.get('subscriberCount', 0)),
                            'video_count': int(channel_stats.get('videoCount', 0)),
                            'view_count': int(channel_stats.get('viewCount', 0)),
                            'subscriber_count_hidden': channel_stats.get('hiddenSubscriberCount', False),
                            'privacy_status': channel_status.get('privacyStatus', ''),
                            'is_linked': channel_status.get('isLinked', False),
                            'long_uploads_status': channel_status.get('longUploadsStatus', ''),
                            'made_for_kids': channel_status.get('madeForKids', False),
                            'self_declared_made_for_kids': channel_status.get('selfDeclaredMadeForKids', False),
                            'topic_ids': channel_topics.get('topicIds', []),
                            'topic_categories': channel_topics.get('topicCategories', []),
                            'keywords': channel_branding.get('channel', {}).get('keywords', ''),
                            'channel_url': f"https://www.youtube.com/channel/{channel_id}"
                        }
            
            print(f"âœ… æˆåŠŸè·å– {len(channel_info_dict)} ä¸ªé¢‘é“çš„è¯¦ç»†ä¿¡æ¯")
        
        # å¤„ç†æœç´¢ç»“æœ
        processed_videos = []
        
        for i, video_id in enumerate(all_video_ids, 1):
            if video_id not in video_details:
                continue
                
            # è·å–è§†é¢‘è¯¦ç»†ä¿¡æ¯
            video = video_details[video_id]
            snippet = video.get('snippet', {})
            
            # è·å–æ‰€æœ‰è¯¦ç»†ä¿¡æ¯
            video_snippet = video.get('snippet', {})
            stats = video.get('statistics', {})
            content_details = video.get('contentDetails', {})
            status = video.get('status', {})
            recording_details = video.get('recordingDetails', {})
            topic_details = video.get('topicDetails', {})
            
            # è·å–é¢‘é“ä¿¡æ¯
            channel_id = snippet.get('channelId', 'N/A')
            channel_info = channel_info_dict.get(channel_id, {})
            
            # æ„å»ºå®Œæ•´çš„è§†é¢‘æ•°æ®ç»“æ„
            video_data = {
                "basic_info": {
                    "kind": item.get('kind', 'N/A'),
                    "etag": item.get('etag', 'N/A'),
                    "video_id": video_id,
                    "video_url": f"https://www.youtube.com/watch?v={video_id}" if video_id != 'N/A' else 'N/A'
                },
                "snippet": {
                    "published_at": snippet.get('publishedAt', 'N/A'),
                    "channel_id": snippet.get('channelId', 'N/A'),
                    "title": snippet.get('title', 'N/A'),
                    "description": snippet.get('description', ''),
                    "channel_title": snippet.get('channelTitle', 'N/A'),
                    "tags": snippet.get('tags', []),
                    "category_id": snippet.get('categoryId', 'N/A'),
                    "live_broadcast_content": snippet.get('liveBroadcastContent', 'N/A'),
                    "default_language": snippet.get('defaultLanguage', 'N/A'),
                    "default_audio_language": snippet.get('defaultAudioLanguage', 'N/A'),
                    "localized": snippet.get('localized', {}),
                    # åˆå¹¶æœç´¢snippetå’Œè¯¦ç»†snippetçš„ä¿¡æ¯
                    "publish_time": video_snippet.get('publishTime', snippet.get('publishTime', 'N/A'))
                },
                "channel_info": {
                    "channel_id": channel_info.get('channel_id', channel_id),
                    "title": channel_info.get('title', snippet.get('channelTitle', 'N/A')),
                    "description": channel_info.get('description', ''),
                    "custom_url": channel_info.get('custom_url', ''),
                    "published_at": channel_info.get('published_at', ''),
                    "country": channel_info.get('country', ''),
                    "default_language": channel_info.get('default_language', ''),
                    "localized_title": channel_info.get('localized_title', ''),
                    "localized_description": channel_info.get('localized_description', ''),
                    "thumbnail_url": channel_info.get('thumbnail_url', ''),
                    "subscriber_count": channel_info.get('subscriber_count', 0),
                    "video_count": channel_info.get('video_count', 0),
                    "view_count": channel_info.get('view_count', 0),
                    "subscriber_count_hidden": channel_info.get('subscriber_count_hidden', False),
                    "privacy_status": channel_info.get('privacy_status', ''),
                    "is_linked": channel_info.get('is_linked', False),
                    "long_uploads_status": channel_info.get('long_uploads_status', ''),
                    "made_for_kids": channel_info.get('made_for_kids', False),
                    "self_declared_made_for_kids": channel_info.get('self_declared_made_for_kids', False),
                    "topic_ids": channel_info.get('topic_ids', []),
                    "topic_categories": channel_info.get('topic_categories', []),
                    "keywords": channel_info.get('keywords', ''),
                    "channel_url": channel_info.get('channel_url', f"https://www.youtube.com/channel/{channel_id}" if channel_id != 'N/A' else '')
                },
                "statistics": {
                    "view_count": int(stats.get('viewCount', 0)) if stats.get('viewCount', '0').isdigit() else 0,
                    "like_count": int(stats.get('likeCount', 0)) if stats.get('likeCount', '0').isdigit() else 0,
                    "dislike_count": int(stats.get('dislikeCount', 0)) if stats.get('dislikeCount', '0').isdigit() else 0,
                    "comment_count": int(stats.get('commentCount', 0)) if stats.get('commentCount', '0').isdigit() else 0,
                    "favorite_count": int(stats.get('favoriteCount', 0)) if stats.get('favoriteCount', '0').isdigit() else 0
                },
                "content_details": {
                    "duration": content_details.get('duration', 'N/A'),
                    "dimension": content_details.get('dimension', 'N/A'),
                    "definition": content_details.get('definition', 'N/A'),
                    "caption": content_details.get('caption', 'N/A'),
                    "licensed_content": content_details.get('licensedContent', 'N/A'),
                    "region_restriction": content_details.get('regionRestriction', {}),
                    "content_rating": content_details.get('contentRating', {}),
                    "projection": content_details.get('projection', 'N/A'),
                    "has_custom_thumbnail": content_details.get('hasCustomThumbnail', 'N/A')
                },
                "status": {
                    "upload_status": status.get('uploadStatus', 'N/A'),
                    "failure_reason": status.get('failureReason', 'N/A'),
                    "rejection_reason": status.get('rejectionReason', 'N/A'),
                    "privacy_status": status.get('privacyStatus', 'N/A'),
                    "publish_at": status.get('publishAt', 'N/A'),
                    "license": status.get('license', 'N/A'),
                    "embeddable": status.get('embeddable', 'N/A'),
                    "public_stats_viewable": status.get('publicStatsViewable', 'N/A'),
                    "made_for_kids": status.get('madeForKids', 'N/A'),
                    "self_declared_made_for_kids": status.get('selfDeclaredMadeForKids', 'N/A')
                },
                "thumbnails": {
                    "default": snippet.get('thumbnails', {}).get('default', {}),
                    "medium": snippet.get('thumbnails', {}).get('medium', {}),
                    "high": snippet.get('thumbnails', {}).get('high', {}),
                    "standard": snippet.get('thumbnails', {}).get('standard', {}),
                    "maxres": snippet.get('thumbnails', {}).get('maxres', {})
                },
                "recording_details": {
                    "location_description": recording_details.get('locationDescription', 'N/A'),
                    "location": recording_details.get('location', {}),
                    "recording_date": recording_details.get('recordingDate', 'N/A')
                },
                "topic_details": {
                    "topic_ids": topic_details.get('topicIds', []),
                    "relevant_topic_ids": topic_details.get('relevantTopicIds', []),
                    "topic_categories": topic_details.get('topicCategories', [])
                },
                "search_metadata": {
                    "search_query": search_query,
                    "result_index": i,
                    "timestamp": datetime.now().isoformat(),
                    "total_results": len(search_response['items']),
                    "search_kind": item.get('id', {}).get('kind', 'N/A')
                }
            }
            
            processed_videos.append(video_data)
            
            # æ‰“å°è§†é¢‘è¯¦ç»†ä¿¡æ¯
            print(f"\n{'='*60}")
            print(f"{i}. ã€{video_data['snippet']['title']}ã€‘")
            print(f"   è§†é¢‘ID: {video_data['basic_info']['video_id']}")
            print(f"   é¢‘é“: {video_data['snippet']['channel_title']}")
            print(f"   å‘å¸ƒæ—¶é—´: {video_data['snippet']['published_at']}")
            print(f"   åˆ†ç±»ID: {video_data['snippet']['category_id']}")
            print(f"   æ ‡ç­¾: {', '.join(video_data['snippet']['tags'][:5]) if video_data['snippet']['tags'] else 'æ— '}")
            print(f"   é»˜è®¤è¯­è¨€: {video_data['snippet']['default_language']}")
            print(f"   \nğŸ“º é¢‘é“ä¿¡æ¯:")
            print(f"   é¢‘é“åç§°: {video_data['channel_info']['title']}")
            print(f"   è®¢é˜…è€…æ•°: {video_data['channel_info']['subscriber_count']:,}")
            print(f"   é¢‘é“å›½å®¶: {video_data['channel_info']['country'] or 'æœªçŸ¥'}")
            print(f"   é¢‘é“è§†é¢‘æ€»æ•°: {video_data['channel_info']['video_count']:,}")
            print(f"   é¢‘é“æ€»è§‚çœ‹æ•°: {video_data['channel_info']['view_count']:,}")
            print(f"   é¢‘é“åˆ›å»ºæ—¶é—´: {video_data['channel_info']['published_at'] or 'æœªçŸ¥'}")
            if video_data['channel_info']['custom_url']:
                print(f"   é¢‘é“è‡ªå®šä¹‰URL: {video_data['channel_info']['custom_url']}")
            if video_data['channel_info']['topic_categories']:
                print(f"   é¢‘é“ä¸»é¢˜: {', '.join(video_data['channel_info']['topic_categories'][:3])}")
            print(f"   \nğŸ“Š ç»Ÿè®¡æ•°æ®:")
            print(f"   è§‚çœ‹æ¬¡æ•°: {video_data['statistics']['view_count']:,}")
            print(f"   ç‚¹èµæ•°: {video_data['statistics']['like_count']:,}")
            print(f"   è¯„è®ºæ•°: {video_data['statistics']['comment_count']:,}")
            print(f"   \nğŸ¬ å†…å®¹è¯¦æƒ…:")
            print(f"   æ—¶é•¿: {video_data['content_details']['duration']}")
            print(f"   æ¸…æ™°åº¦: {video_data['content_details']['definition']}")
            print(f"   å­—å¹•: {video_data['content_details']['caption']}")
            print(f"   è®¸å¯å†…å®¹: {video_data['content_details']['licensed_content']}")
            print(f"   \nğŸ”’ çŠ¶æ€ä¿¡æ¯:")
            print(f"   ä¸Šä¼ çŠ¶æ€: {video_data['status']['upload_status']}")
            print(f"   éšç§çŠ¶æ€: {video_data['status']['privacy_status']}")
            print(f"   è®¸å¯è¯: {video_data['status']['license']}")
            print(f"   å¯åµŒå…¥: {video_data['status']['embeddable']}")
            print(f"   å„¿ç«¥å†…å®¹: {video_data['status']['made_for_kids']}")
            if video_data['topic_details']['topic_categories']:
                print(f"   \nğŸ·ï¸ ä¸»é¢˜åˆ†ç±»: {', '.join(video_data['topic_details']['topic_categories'][:3])}")
            
            # å‘é€åˆ°webhookï¼ˆå¦‚æœæä¾›äº†URLï¼‰
            if webhook_url:
                print(f"   \nğŸ“¤ å‘é€åˆ°webhook...")
                send_success = send_to_webhook(video_data, webhook_url)
                if send_success:
                    print(f"   âœ… å‘é€æˆåŠŸ")
                else:
                    print(f"   âŒ å‘é€å¤±è´¥")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.5)
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(processed_videos)} ä¸ªè§†é¢‘")
        return processed_videos
        
    except googleapiclient.errors.HttpError as e:
        error_msg = f"YouTube APIé”™è¯¯ {e.resp.status}: {e.content.decode('utf-8')}"
        print(f"âŒ {error_msg}")
        raise Exception(error_msg)
    except Exception as e:
        error_msg = f"æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(f"âŒ {error_msg}")
        raise Exception(error_msg)

def main():
    """ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå‚æ•°å’Œç¯å¢ƒå˜é‡ï¼Œæ”¯æŒæœç´¢ã€è¯„è®ºè·å–å’Œé¢‘é“è§†é¢‘è·å–ä¸‰ç§æ¨¡å¼"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    api_key = os.getenv('YOUTUBE_API_KEY')
    mode = os.getenv('MODE', 'search')  # é»˜è®¤ä¸ºæœç´¢æ¨¡å¼
    
    # æœç´¢æ¨¡å¼å‚æ•°
    search_query = os.getenv('SEARCH_QUERY')
    max_results = int(os.getenv('MAX_RESULTS', '25'))
    
    # è¯„è®ºæ¨¡å¼å‚æ•°
    video_id = os.getenv('VIDEO_ID')
    max_comments = int(os.getenv('MAX_COMMENTS', '50'))
    
    # é¢‘é“æ¨¡å¼å‚æ•°
    channel_handle = os.getenv('CHANNEL_HANDLE')
    max_videos = int(os.getenv('MAX_VIDEOS', '50'))
    
    # é€šç”¨å‚æ•°
    webhook_url = os.getenv('WEBHOOK_URL')
    
    # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆçº§æ›´é«˜
    if len(sys.argv) > 1:
        mode = sys.argv[1]  # ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯æ¨¡å¼
    if len(sys.argv) > 2:
        if mode == 'search':
            search_query = sys.argv[2]
        elif mode == 'comments':
            video_id = sys.argv[2]
        elif mode == 'channel':
            channel_handle = sys.argv[2]
    if len(sys.argv) > 3:
        if mode == 'search':
            max_results = int(sys.argv[3])
        elif mode == 'comments':
            max_comments = int(sys.argv[3])
        elif mode == 'channel':
            max_videos = int(sys.argv[3])
    if len(sys.argv) > 4:
        api_key = sys.argv[4]  # APIå¯†é’¥ä½œä¸ºç¬¬4ä¸ªå‚æ•°
    if len(sys.argv) > 5:
        webhook_url = sys.argv[5]  # webhook_urlä½œä¸ºç¬¬5ä¸ªå‚æ•°
    
    # éªŒè¯å¿…éœ€å‚æ•°
    if not api_key:
        print("âŒ é”™è¯¯: æœªæä¾›YouTube APIå¯†é’¥")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ YOUTUBE_API_KEY æˆ–ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°ä¼ å…¥")
        sys.exit(1)
    
    # æ ¹æ®æ¨¡å¼éªŒè¯å‚æ•°
    if mode == 'search':
        if not search_query:
            print("âŒ é”™è¯¯: æœç´¢æ¨¡å¼ä¸‹æœªæä¾›æœç´¢å…³é”®è¯")
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ SEARCH_QUERY æˆ–ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°ä¼ å…¥")
            sys.exit(1)
    elif mode == 'comments':
        if not video_id:
            print("âŒ é”™è¯¯: è¯„è®ºæ¨¡å¼ä¸‹æœªæä¾›è§†é¢‘ID")
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ VIDEO_ID æˆ–ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°ä¼ å…¥")
            sys.exit(1)
    elif mode == 'channel':
        if not channel_handle:
            print("âŒ é”™è¯¯: é¢‘é“æ¨¡å¼ä¸‹æœªæä¾›é¢‘é“Handle")
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ CHANNEL_HANDLE æˆ–ä½œä¸ºå‘½ä»¤è¡Œå‚æ•°ä¼ å…¥")
            sys.exit(1)
    else:
        print("âŒ é”™è¯¯: ä¸æ”¯æŒçš„æ¨¡å¼ï¼Œè¯·ä½¿ç”¨ 'search'ã€'comments' æˆ– 'channel'")
        sys.exit(1)
    
    print("=" * 60)
    if mode == 'search':
        print("ğŸš€ YouTubeæœç´¢API - GitHub Webhookç‰ˆæœ¬")
        print("=" * 60)
        print(f"ğŸ”‘ APIå¯†é’¥: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        print(f"ğŸ” æœç´¢å…³é”®è¯: {search_query}")
        print(f"ğŸ“Š æœ€å¤§ç»“æœæ•°: {max_results}")
    elif mode == 'comments':
        print("ğŸ’¬ YouTubeè¯„è®ºè·å–API - GitHub Webhookç‰ˆæœ¬")
        print("=" * 60)
        print(f"ğŸ”‘ APIå¯†é’¥: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        print(f"ğŸ¥ è§†é¢‘ID: {video_id}")
        print(f"ğŸ’¬ æœ€å¤§è¯„è®ºæ•°: {max_comments}")
    elif mode == 'channel':
        print("ğŸ“º YouTubeé¢‘é“è§†é¢‘è·å–API - GitHub Webhookç‰ˆæœ¬")
        print("=" * 60)
        print(f"ğŸ”‘ APIå¯†é’¥: {'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        print(f"ğŸ“º é¢‘é“Handle: {channel_handle}")
        print(f"ğŸ¬ æœ€å¤§è§†é¢‘æ•°: {max_videos}")
    
    print(f"ğŸ“¤ Webhook URL: {'å·²è®¾ç½®' if webhook_url else 'æœªè®¾ç½®'}")
    print("=" * 60)
    
    try:
        if mode == 'search':
            # æ‰§è¡Œæœç´¢
            results = search_youtube_videos(
                api_key=api_key,
                search_query=search_query,
                max_results=max_results,
                webhook_url=webhook_url
            )
            
            # è¾“å‡ºç»“æœæ‘˜è¦
            if results:
                print(f"\nğŸ“‹ æœç´¢ç»“æœæ‘˜è¦:")
                for i, video in enumerate(results[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
                    basic_info = video['basic_info']
                    stats = video['statistics']
                    print(f"{i}. {basic_info['title'][:60]}...")
                    print(f"   ğŸ“º é¢‘é“: {basic_info['channel_title']}")
                    print(f"   ğŸ‘€ è§‚çœ‹: {stats['view_count']:,} | ğŸ‘ ç‚¹èµ: {stats['like_count']:,}")
                    print(f"   ğŸ”— é“¾æ¥: {basic_info['video_url']}")
                    print()
            
            # å¦‚æœæ²¡æœ‰webhookï¼Œå°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
            if not webhook_url:
                output_file = f"youtube_search_results_{int(time.time())}.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        elif mode == 'comments':
            # æ‰§è¡Œè¯„è®ºè·å–
            results = get_video_comments(
                api_key=api_key,
                video_id=video_id,
                max_comments=max_comments,
                webhook_url=webhook_url
            )
            
            # è¾“å‡ºç»“æœæ‘˜è¦
            if results and 'comments' in results and len(results['comments']) > 0:
                video_info = results['video_info']
                comments = results['comments']
                print(f"\nğŸ“‹ è¯„è®ºè·å–ç»“æœæ‘˜è¦:")
                if 'title' in video_info and 'channel_title' in video_info:
                    print(f"ğŸ¥ è§†é¢‘: {video_info['title'][:60]}...")
                    print(f"ğŸ“º é¢‘é“: {video_info['channel_title']}")
                print(f"ğŸ’¬ è·å–åˆ° {len(comments)} æ¡è¯„è®º")
                if comments:
                    print(f"\nğŸ”¥ çƒ­é—¨è¯„è®ºé¢„è§ˆ:")
                    for i, comment in enumerate(comments[:3], 1):  # æ˜¾ç¤ºå‰3æ¡è¯„è®º
                        print(f"{i}. ğŸ‘¤ {comment['author_name']}")
                        print(f"   ğŸ’¬ {comment['text'][:100]}...")
                        print(f"   ğŸ‘ {comment['like_count']:,} èµ | ğŸ“… {comment['published_at']}")
                        print()
            elif results and 'error' in results:
                print(f"\nâŒ è·å–è¯„è®ºå¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"\nâŒ æœªèƒ½è·å–åˆ°è¯„è®ºæ•°æ®")
            
            # å¦‚æœæ²¡æœ‰webhookï¼Œå°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
            if not webhook_url:
                output_file = f"youtube_comments_{video_id}_{int(time.time())}.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        elif mode == 'channel':
            # æ‰§è¡Œé¢‘é“è§†é¢‘è·å–
            results = get_channel_videos(
                api_key=api_key,
                handle=channel_handle,
                max_results=max_videos,
                webhook_url=webhook_url
            )
            
            # è¾“å‡ºç»“æœæ‘˜è¦
            if results and 'videos' in results and len(results['videos']) > 0:
                channel_info = results['channel_info']
                videos = results['videos']
                print(f"\nğŸ“‹ é¢‘é“è§†é¢‘è·å–ç»“æœæ‘˜è¦:")
                print(f"ğŸ“º é¢‘é“: {channel_info['title'][:60]}...")
                print(f"ğŸ‘¥ è®¢é˜…è€…: {channel_info['subscriber_count']:,} | ğŸ¬ æ€»è§†é¢‘: {channel_info['video_count']:,}")
                print(f"ğŸ“Š è·å–åˆ° {len(videos)} ä¸ªè§†é¢‘")
                if videos:
                    print(f"\nğŸ”¥ çƒ­é—¨è§†é¢‘é¢„è§ˆ:")
                    for i, video in enumerate(videos[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ªè§†é¢‘
                        print(f"{i}. ğŸ¥ {video['title'][:60]}...")
                        print(f"   ğŸ‘€ è§‚çœ‹: {video['view_count']:,} | ğŸ‘ ç‚¹èµ: {video['like_count']:,}")
                        print(f"   ğŸ“… å‘å¸ƒ: {video['published_at']} | ğŸ”— {video['video_url']}")
                        print()
            elif results and 'error' in results:
                print(f"\nâŒ è·å–é¢‘é“è§†é¢‘å¤±è´¥: {results.get('error', 'æœªçŸ¥é”™è¯¯')}")
            else:
                print(f"\nâŒ æœªèƒ½è·å–åˆ°é¢‘é“è§†é¢‘æ•°æ®")
            
            # å¦‚æœæ²¡æœ‰webhookï¼Œå°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
            if not webhook_url:
                # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶åï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
                safe_handle = channel_handle.replace('https://www.youtube.com/', '').replace('/', '_').replace(':', '_')
                output_file = f"youtube_channel_{safe_handle}_{int(time.time())}.json"
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        print("\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        
    except Exception as e:
        print(f"\nğŸ’¥ ä»»åŠ¡å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()